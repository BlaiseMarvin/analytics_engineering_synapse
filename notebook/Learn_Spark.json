{
	"name": "Learn_Spark",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "coursepool",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "73511f85-fc6e-4c63-b2d3-2a26297f63dd"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/bb4563b7-621b-4adf-a14c-567e4b069294/resourceGroups/synapse-course-rg/providers/Microsoft.Synapse/workspaces/synapse-course-us/bigDataPools/coursepool",
				"name": "coursepool",
				"type": "Spark",
				"endpoint": "https://synapse-course-us.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/coursepool",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 10,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql import SparkSession\n",
					"from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
					"import pyspark.sql.functions as func"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"source": [
					"# check out the spark session\n",
					"print(spark)"
				],
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"source": [
					"# define the datatypes:\n",
					"myschema = StructType([\\\n",
					"    StructField(\"userID\",IntegerType(),True),\n",
					"    StructField(\"name\", StringType(), True),\n",
					"    StructField(\"age\",IntegerType(),True),\n",
					"    StructField(\"friends\", IntegerType(),True)\n",
					"])"
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"source": [
					"people = spark.read.format(\"csv\")\\\n",
					"                    .schema(myschema)\\\n",
					"                    .option(\"path\",\"abfss://nyc-taxi-data@syanpsecoursedlblaise.dfs.core.windows.net/spark_resources/fakefriends.csv\")\\\n",
					"                    .load()"
				],
				"execution_count": 4
			},
			{
				"cell_type": "code",
				"source": [
					"people"
				],
				"execution_count": 5
			},
			{
				"cell_type": "code",
				"source": [
					"# performing transformations\n",
					"output = people.select(people.userID, people.name,\\\n",
					"                        people.age, people.friends)\\\n",
					"                .where(people.age<30).withColumn('insert_ts', func.current_timestamp())\\\n",
					"                .orderBy(people.userID)"
				],
				"execution_count": 6
			},
			{
				"cell_type": "code",
				"source": [
					"output.show()"
				],
				"execution_count": 7
			},
			{
				"cell_type": "code",
				"source": [
					"output.count()"
				],
				"execution_count": 8
			},
			{
				"cell_type": "code",
				"source": [
					"# creating a temp view:\n",
					"output.createOrReplaceTempView(\"Peoples\")"
				],
				"execution_count": 9
			},
			{
				"cell_type": "code",
				"source": [
					"# running a simple sql query \n",
					"spark.sql(\"select name, age, friends, insert_ts from Peoples\").show()"
				],
				"execution_count": 10
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"Ops Mgmt "
				]
			},
			{
				"cell_type": "code",
				"source": [
					"ops_path = \"abfss://nyc-taxi-data@syanpsecoursedlblaise.dfs.core.windows.net/spark_resources/operations_management.csv\""
				],
				"execution_count": 11
			},
			{
				"cell_type": "code",
				"source": [
					"print(spark.version)"
				],
				"execution_count": 12
			},
			{
				"cell_type": "code",
				"source": [
					"data = spark.read.format(\"csv\")\\\n",
					"                 .option(\"inferSchema\",\"true\")\\\n",
					"                 .option(\"header\",\"true\")\\\n",
					"                 .option(\"path\",ops_path)\\\n",
					"                 .load()"
				],
				"execution_count": 13
			},
			{
				"cell_type": "code",
				"source": [
					"# view schema\n",
					"data.printSchema()"
				],
				"execution_count": 14
			},
			{
				"cell_type": "code",
				"source": [
					"data_2 = data.select(\"industry\",\"value\")\\\n",
					"             .filter((func.col(\"value\")>200) & (func.col(\"industry\") != \"total\"))\\\n",
					"             .orderBy(func.desc(\"value\"))"
				],
				"execution_count": 20
			},
			{
				"cell_type": "code",
				"source": [
					"data_2.printSchema()"
				],
				"execution_count": 21
			},
			{
				"cell_type": "code",
				"source": [
					"data_2.show(5)"
				],
				"execution_count": 22
			},
			{
				"cell_type": "code",
				"source": [
					"data_2.createOrReplaceTempView(\"data\")"
				],
				"execution_count": 23
			},
			{
				"cell_type": "code",
				"source": [
					"spark.sql(\"SELECT industry, value FROM data WHERE value > 200 AND industry != 'total' \").show(5)"
				],
				"execution_count": 25
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"Spark SQL Tables and Views:"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"spark.catalog.listDatabases()"
				],
				"execution_count": 26
			},
			{
				"cell_type": "code",
				"source": [
					"data.rdd.getNumPartitions()"
				],
				"execution_count": 28
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"Taxi Data:"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"df = spark.read.format(\"parquet\")\\\n",
					"                .option(\"path\",\"abfss://nyc-taxi-data@syanpsecoursedlblaise.dfs.core.windows.net/spark_resources/fhvhv_tripdata_2021-02.parquet\")\\\n",
					"                .load()"
				],
				"execution_count": 46
			},
			{
				"cell_type": "code",
				"source": [
					"df = df.repartition(8)"
				],
				"execution_count": 47
			},
			{
				"cell_type": "code",
				"source": [
					"df.show()"
				],
				"execution_count": 48
			},
			{
				"cell_type": "code",
				"source": [
					"df.rdd.getNumPartitions()"
				],
				"execution_count": 31
			},
			{
				"cell_type": "code",
				"source": [
					"df = df.repartition(8)"
				],
				"execution_count": 39
			},
			{
				"cell_type": "code",
				"source": [
					"df.show()"
				],
				"execution_count": 40
			},
			{
				"cell_type": "code",
				"source": [
					"spark.conf.get(\"spark.sql.adaptive.skewJoin.enabled\")"
				],
				"execution_count": 41
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"Handling Data Skewness:"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql import DataFrame\n",
					"import pyspark.sql.functions as F"
				],
				"execution_count": 49
			},
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql import SparkSession"
				],
				"execution_count": 51
			},
			{
				"cell_type": "code",
				"source": [
					"def prepare_trips_data(spark: SparkSession):\n",
					"    pu_loc_to_change = [\n",
					"        236, 132, 161, 186, 142, 141, 48, 239, 170, 162, 230, 163, 79, 234, 263, 140, 238, 107, 68, 138, 229, 249,\n",
					"        237, 164, 90, 43, 100, 246, 231, 262, 113, 233, 143, 137, 114, 264, 148, 151\n",
					"    ]\n",
					"    res_df = spark.read.format(\"parquet\")\\\n",
					"                        .option(\"path\",\"abfss://nyc-taxi-data@syanpsecoursedlblaise.dfs.core.windows.net/spark_resources/data/*.parquet\")\\\n",
					"                        .load()\\\n",
					"                       .withColumn(\n",
					"                            \"PULocationID\",\n",
					"                            F.when(F.col(\"PULocationID\").isin(pu_loc_to_change),F.lit(237)).otherwise(F.col(\"PULocationID\"))\n",
					"                       )\n",
					"    return res_df"
				],
				"execution_count": 76
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"Detecting Skew:"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"def join_on_skewed_data(spark: SparkSession):\n",
					"    trips_data = prepare_trips_data(spark=spark)\n",
					"    location_details_data = spark.read.format(\"csv\")\\\n",
					"                                      .option(\"path\",\"abfss://nyc-taxi-data@syanpsecoursedlblaise.dfs.core.windows.net/spark_resources/taxi+_zone_lookup.csv\")\\\n",
					"                                      .option(\"header\",\"true\")\\\n",
					"                                      .load()\n",
					"    \n",
					"    trips_with_pickup_location_details = trips_data\\\n",
					"                                        .join(location_details_data, F.col(\"trips_data.PULocationID\") == F.col(\"location_details_data.LocationID\"),\"inner\")\n",
					"    \n",
					"    trips_with_pickup_location_details\\\n",
					"    .groupBy(\"Zone\")\\\n",
					"    .agg(F.avg(\"trip_distance\").alias(\"avg_trip_distance\"))\\\n",
					"    .sort(F.col(\"avg_trip_distance\").desc())\\\n",
					"    .show(truncate=False, n=1000)\n",
					"\n",
					"    trips_with_pickup_location_details\\\n",
					"    .groupBy(\"Borough\")\\\n",
					"    .agg(F.avg(\"trip_distance\").alias(\"avg_trip_distance\"))\\\n",
					"    .sort(F.col(\"avg_trip_distance\").desc())\\\n",
					"    .show(truncate=False, n=1000)"
				],
				"execution_count": 85
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"To observe skewness, Adaptive Query Execution needs to be disabled. Disable broadcast joins as well."
				]
			},
			{
				"cell_type": "code",
				"source": [
					"#\n",
					"spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\n",
					"spark.conf.set(\"spark.sql.shuffle.partitions\", \"201\")\n",
					"spark.conf.set(\"spark.sql.adaptive.enabled\", \"false\")"
				],
				"execution_count": 86
			},
			{
				"cell_type": "code",
				"source": [
					"join_on_skewed_data(spark=spark)"
				],
				"execution_count": 87
			},
			{
				"cell_type": "code",
				"source": [
					"test_df = prepare_trips_data(spark = spark)"
				],
				"execution_count": 74
			},
			{
				"cell_type": "code",
				"source": [
					"location_details_data = spark.read.format(\"csv\")\\\n",
					"                                      .option(\"path\",\"abfss://nyc-taxi-data@syanpsecoursedlblaise.dfs.core.windows.net/spark_resources/taxi+_zone_lookup.csv\")\\\n",
					"                                      .option(\"header\",\"true\")\\\n",
					"                                      .load()"
				],
				"execution_count": 88
			},
			{
				"cell_type": "code",
				"source": [
					"test_df.printSchema()"
				],
				"execution_count": 89
			},
			{
				"cell_type": "code",
				"source": [
					"location_details_data.printSchema()"
				],
				"execution_count": 90
			},
			{
				"cell_type": "code",
				"source": [
					"trips_with_pickup_location_details = test_df.join(location_details_data, F.col(\"PULocationID\") == F.col(\"LocationID\"), \"inner\")"
				],
				"execution_count": 92
			},
			{
				"cell_type": "code",
				"source": [
					"trips_with_pickup_location_details\\\n",
					"    .groupBy(\"Zone\")\\\n",
					"    .agg(F.avg(\"trip_distance\").alias(\"avg_trip_distance\"))\\\n",
					"    .sort(F.col(\"avg_trip_distance\").desc())\\\n",
					"    .show(truncate=False, n=1000)"
				],
				"execution_count": 93
			},
			{
				"cell_type": "code",
				"source": [
					"trips_with_pickup_location_details\\\n",
					"    .groupBy(\"Borough\")\\\n",
					"    .agg(F.avg(\"trip_distance\").alias(\"avg_trip_distance\"))\\\n",
					"    .sort(F.col(\"avg_trip_distance\").desc())\\\n",
					"    .show(truncate=False, n=1000)"
				],
				"execution_count": 94
			},
			{
				"cell_type": "code",
				"source": [
					""
				],
				"execution_count": null
			}
		]
	}
}